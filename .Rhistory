plot(model_lm)
#  GAM
library(mgcv)
model_gam <- gam(GDP_Growth ~ s(Interest_Rate) + s(Unemployment_Rate) + s(Year), data = inflation_data)
summary(model_gam)
par(mfrow = c(1, 3))
plot(model_gam, se = TRUE, col = "darkgreen")
# Set up 1 row with 3 plots
par(mfrow = c(1, 3))  # or use c(2,2) if you want 2 rows
# Unemployment vs Inflation
loess_unemp <- loess(Inflation ~ Unemployment_Rate, data = inflation_data, span = 0.6)
x_unemp <- seq(min(inflation_data$Unemployment_Rate), max(inflation_data$Unemployment_Rate), length.out = 100)
pred_unemp <- predict(loess_unemp, newdata = data.frame(Unemployment_Rate = x_unemp), se = TRUE)
plot(inflation_data$Unemployment_Rate, inflation_data$Inflation,
main = "Kernel Regression: Unemployment vs Inflation",
xlab = "Unemployment Rate (%)", ylab = "Inflation (%)", pch = 19, col = "gray")
lines(x_unemp, pred_unemp$fit, col = "blue", lwd = 2)
lines(x_unemp, pred_unemp$fit + 1.96 * pred_unemp$se.fit, col = "blue", lty = 2)
lines(x_unemp, pred_unemp$fit - 1.96 * pred_unemp$se.fit, col = "blue", lty = 2)
# Interest Rate vs Inflation
loess_int <- loess(Inflation ~ Interest_Rate, data = inflation_data, span = 0.6)
x_int <- seq(min(inflation_data$Interest_Rate), max(inflation_data$Interest_Rate), length.out = 100)
pred_int <- predict(loess_int, newdata = data.frame(Interest_Rate = x_int), se = TRUE)
plot(inflation_data$Interest_Rate, inflation_data$Inflation,
main = "Kernel Regression: Interest Rate vs Inflation",
xlab = "Interest Rate (%)", ylab = "Inflation (%)", pch = 19, col = "gray")
lines(x_int, pred_int$fit, col = "red", lwd = 2)
lines(x_int, pred_int$fit + 1.96 * pred_int$se.fit, col = "red", lty = 2)
lines(x_int, pred_int$fit - 1.96 * pred_int$se.fit, col = "red", lty = 2)
# GDP Growth vs Inflation
loess_gdp <- loess(Inflation ~ GDP_Growth, data = inflation_data, span = 0.6)
x_gdp <- seq(min(inflation_data$GDP_Growth), max(inflation_data$GDP_Growth), length.out = 100)
pred_gdp <- predict(loess_gdp, newdata = data.frame(GDP_Growth = x_gdp), se = TRUE)
plot(inflation_data$GDP_Growth, inflation_data$Inflation,
main = "Kernel Regression: GDP Growth vs Inflation",
xlab = "GDP Growth (%)", ylab = "Inflation (%)", pch = 19, col = "gray")
lines(x_gdp, pred_gdp$fit, col = "darkgreen", lwd = 2)
lines(x_gdp, pred_gdp$fit + 1.96 * pred_gdp$se.fit, col = "darkgreen", lty = 2)
lines(x_gdp, pred_gdp$fit - 1.96 * pred_gdp$se.fit, col = "darkgreen", lty = 2)
setwd("C:/UCLA/404/Final Projext")
library(mgcv)
inflation_data <- read.csv("Final_Inflation_Dataset__USA_.csv", stringsAsFactors = FALSE)
# inflation_data columns: Year, Inflation, GDP_Growth, Interest_Rate, Unemployment_Rate
# Load libraries
library(ggplot2)
library(dplyr)
library(corrplot)
library(GGally)
library(gridExtra)
# 1. Summary Statistics
summary(inflation_data)
sapply(inflation_data[, -1], sd)  # Standard deviation (excluding Year)
#Plots
# Time Series Plots with Year on x-axis
p1 <- ggplot(inflation_data, aes(x = Inflation, y = GDP_Growth)) +
geom_line(color = "steelblue") +
labs(title = "Inflation Rate Over Time", x = "Year", y = "GDP Growth (%)")
p3 <- ggplot(inflation_data, aes(x = Inflation, y = Interest_Rate)) +
geom_line(color = "red") +
labs(title = "Interest Rate Over Time", x = "Year", y = "Interest Rate (%)")
p4 <- ggplot(inflation_data, aes(x = Inflation, y = Unemployment_Rate)) +
geom_line(color = "purple") +
labs(title = "Unemployment Rate Over Time", x = "Year", y = "Unemployment Rate (%)")
# Arrange in 2x2 layout
grid.arrange(p1, p3, p4, ncol = 2)
# 3. Correlation Matrix
cor_matrix <- cor(inflation_data[, -1], use = "complete.obs")
corrplot(cor_matrix, method = "circle", type = "upper", tl.cex = 0.8)
# 6. Check for missing data
colSums(is.na(inflation_data))
str(inflation_data)
summary(inflation_data)
inflation_data <- inflation_data[, 1:5]
#Linear Model
model_lm <- lm(GDP_Growth ~ Interest_Rate + Unemployment_Rate + Year, data = inflation_data)
summary(model_lm)
# Diagnostic plots
par(mfrow = c(2, 2))
plot(model_lm)
#Kernel Regression
par(mfrow = c(1, 3))
# Unemployment vs Inflation
loess_unemp <- loess(Inflation ~ Unemployment_Rate, data = inflation_data, span = 0.6)
x_unemp <- seq(min(inflation_data$Unemployment_Rate), max(inflation_data$Unemployment_Rate), length.out = 100)
pred_unemp <- predict(loess_unemp, newdata = data.frame(Unemployment_Rate = x_unemp), se = TRUE)
plot(inflation_data$Unemployment_Rate, inflation_data$Inflation,
main = "Kernel Regression: Unemployment vs Inflation",
xlab = "Unemployment Rate (%)", ylab = "Inflation by Year", pch = 19, col = "gray")
lines(x_unemp, pred_unemp$fit, col = "blue", lwd = 2)
lines(x_unemp, pred_unemp$fit + 1.96 * pred_unemp$se.fit, col = "blue", lty = 2)
lines(x_unemp, pred_unemp$fit - 1.96 * pred_unemp$se.fit, col = "blue", lty = 2)
# Interest Rate vs Inflation
loess_int <- loess(Inflation ~ Interest_Rate, data = inflation_data, span = 0.6)
x_int <- seq(min(inflation_data$Interest_Rate), max(inflation_data$Interest_Rate), length.out = 100)
pred_int <- predict(loess_int, newdata = data.frame(Interest_Rate = x_int), se = TRUE)
plot(inflation_data$Interest_Rate, inflation_data$Inflation,
main = "Kernel Regression: Interest Rate vs Inflation",
xlab = "Interest Rate (%)", ylab = "Inflation by Year", pch = 19, col = "gray")
lines(x_int, pred_int$fit, col = "red", lwd = 2)
lines(x_int, pred_int$fit + 1.96 * pred_int$se.fit, col = "red", lty = 2)
lines(x_int, pred_int$fit - 1.96 * pred_int$se.fit, col = "red", lty = 2)
# GDP Growth vs Inflation
loess_gdp <- loess(Inflation ~ GDP_Growth, data = inflation_data, span = 0.6)
x_gdp <- seq(min(inflation_data$GDP_Growth), max(inflation_data$GDP_Growth), length.out = 100)
pred_gdp <- predict(loess_gdp, newdata = data.frame(GDP_Growth = x_gdp), se = TRUE)
plot(inflation_data$GDP_Growth, inflation_data$Inflation,
main = "Kernel Regression: GDP Growth vs Inflation",
xlab = "GDP Growth (%)", ylab = "Inflation by Year", pch = 19, col = "gray")
lines(x_gdp, pred_gdp$fit, col = "darkgreen", lwd = 2)
lines(x_gdp, pred_gdp$fit + 1.96 * pred_gdp$se.fit, col = "darkgreen", lty = 2)
lines(x_gdp, pred_gdp$fit - 1.96 * pred_gdp$se.fit, col = "darkgreen", lty = 2)
#  GAM
library(mgcv)
model_gam <- gam(GDP_Growth ~ s(Interest_Rate) + s(Unemployment_Rate) + s(Year), data = inflation_data)
summary(model_gam)
par(mfrow = c(1, 3))
plot(model_gam, se = TRUE, col = "darkgreen")
setwd("C:/UCLA/404/Final Projext")
library(mgcv)
inflation_data <- read.csv("Final_Inflation_Dataset__USA_.csv", stringsAsFactors = FALSE)
# inflation_data columns: Year, Inflation, GDP_Growth, Interest_Rate, Unemployment_Rate
# Load libraries
library(ggplot2)
library(dplyr)
library(corrplot)
library(GGally)
library(gridExtra)
# 1. Summary Statistics
summary(inflation_data)
sapply(inflation_data[, -1], sd)  # Standard deviation (excluding Year)
#Plots
# Time Series Plots with Year on x-axis
p1 <- ggplot(inflation_data, aes(x = Inflation, y = GDP_Growth)) +
geom_line(color = "steelblue") +
labs(title = "Inflation Rate Over Time", x = "Year", y = "GDP Growth (%)")
p3 <- ggplot(inflation_data, aes(x = Inflation, y = Interest_Rate)) +
geom_line(color = "red") +
labs(title = "Interest Rate Over Time", x = "Year", y = "Interest Rate (%)")
p4 <- ggplot(inflation_data, aes(x = Inflation, y = Unemployment_Rate)) +
geom_line(color = "purple") +
labs(title = "Unemployment Rate Over Time", x = "Year", y = "Unemployment Rate (%)")
# Arrange in 2x2 layout
grid.arrange(p1, p3, p4, ncol = 2)
# 3. Correlation Matrix
cor_matrix <- cor(inflation_data[, -1], use = "complete.obs")
corrplot(cor_matrix, method = "circle", type = "upper", tl.cex = 0.8)
str(inflation_data)
summary(inflation_data)
inflation_data <- inflation_data[, 1:5]
#Linear Model
model_lm <- lm(GDP_Growth ~ Interest_Rate + Unemployment_Rate + Year, data = inflation_data)
summary(model_lm)
# Diagnostic plots
par(mfrow = c(2, 2))
plot(model_lm)
#  GAM
library(mgcv)
model_gam <- gam(GDP_Growth ~ s(Interest_Rate) + s(Unemployment_Rate) + s(Year), data = inflation_data)
summary(model_gam)
#Kernel Regression
par(mfrow = c(1, 3))
# Unemployment vs Inflation
loess_unemp <- loess(Inflation ~ Unemployment_Rate, data = inflation_data, span = 0.6)
x_unemp <- seq(min(inflation_data$Unemployment_Rate), max(inflation_data$Unemployment_Rate), length.out = 100)
pred_unemp <- predict(loess_unemp, newdata = data.frame(Unemployment_Rate = x_unemp), se = TRUE)
plot(inflation_data$Unemployment_Rate, inflation_data$Inflation,
main = "Kernel Regression: Unemployment vs Inflation",
xlab = "Unemployment Rate (%)", ylab = "Inflation by Year", pch = 19, col = "gray")
lines(x_unemp, pred_unemp$fit, col = "blue", lwd = 2)
lines(x_unemp, pred_unemp$fit + 1.96 * pred_unemp$se.fit, col = "blue", lty = 2)
lines(x_unemp, pred_unemp$fit - 1.96 * pred_unemp$se.fit, col = "blue", lty = 2)
# Interest Rate vs Inflation
loess_int <- loess(Inflation ~ Interest_Rate, data = inflation_data, span = 0.6)
x_int <- seq(min(inflation_data$Interest_Rate), max(inflation_data$Interest_Rate), length.out = 100)
pred_int <- predict(loess_int, newdata = data.frame(Interest_Rate = x_int), se = TRUE)
plot(inflation_data$Interest_Rate, inflation_data$Inflation,
main = "Kernel Regression: Interest Rate vs Inflation",
xlab = "Interest Rate (%)", ylab = "Inflation by Year", pch = 19, col = "gray")
lines(x_int, pred_int$fit, col = "red", lwd = 2)
lines(x_int, pred_int$fit + 1.96 * pred_int$se.fit, col = "red", lty = 2)
lines(x_int, pred_int$fit - 1.96 * pred_int$se.fit, col = "red", lty = 2)
# GDP Growth vs Inflation
loess_gdp <- loess(Inflation ~ GDP_Growth, data = inflation_data, span = 0.6)
x_gdp <- seq(min(inflation_data$GDP_Growth), max(inflation_data$GDP_Growth), length.out = 100)
pred_gdp <- predict(loess_gdp, newdata = data.frame(GDP_Growth = x_gdp), se = TRUE)
plot(inflation_data$GDP_Growth, inflation_data$Inflation,
main = "Kernel Regression: GDP Growth vs Inflation",
xlab = "GDP Growth (%)", ylab = "Inflation by Year", pch = 19, col = "gray")
lines(x_gdp, pred_gdp$fit, col = "darkgreen", lwd = 2)
lines(x_gdp, pred_gdp$fit + 1.96 * pred_gdp$se.fit, col = "darkgreen", lty = 2)
lines(x_gdp, pred_gdp$fit - 1.96 * pred_gdp$se.fit, col = "darkgreen", lty = 2)
# Load required libraries
library(ggplot2)
library(readr)
library(dplyr)
library(GGally)
library(randomForest)
library(caret)
# Load the data
df <- read_csv("Fire_With_Climate_Joined.csv")
df <- read.csv ("Fire_With_Climate_Joined.csv")
df$fire_severity <- with(df, ifelse(frp=0,0,
ifelse(frp <= 50,1,2) ) )
df <- read.csv ("Fire_With_Climate_Joined.csv")
df$fire_severity <- with(df, ifelse(frp==0,0,
ifelse(frp <= 50,1,2) ) )
df$fire_severity <- as.factor(df$fire_severity)
#Select predictor Variables
df_model <- df %>%
select(fire_severity, vpd, tmmx_C, pr, vs) %>%
na.omit()
#TRain test split
set.seed(123)
train_index <- createDataPartition(df_model$fire_severity, p = 0.7, list = FALSE)
train <- df_model[train_index, ]
test <- df_model[-train_index, ]
#  random forest classifier
rf_model <- randomForest(fire_severity ~ ., data = train, ntree= 100, importance=true)
df <- read.csv ("Fire_With_Climate_Joined.csv")
df$fire_severity <- with(df, ifelse(frp==0,0,
ifelse(frp <= 50,1,2) ) )
df$fire_severity <- as.factor(df$fire_severity)
#Select predictor Variables
df_model <- df %>%
select(fire_severity, vpd, tmmx_C, pr, vs) %>%
na.omit()
#TRain test split
set.seed(123)
train_index <- createDataPartition(df_model$fire_severity, p = 0.7, list = FALSE)
train <- df_model[train_index, ]
test <- df_model[-train_index, ]
#  random forest classifier
rf_model <- randomForest(fire_severity ~ ., data = train, ntree= 100, importance=TRUE)
#Predictions on test set
preds<- predict(rf_model, newdata = test)
#Evaluate performance
conf_mat <- confusionMatrix(preds, test$fire_severity)
print(conf_mat)
# View variable importance
importance(rf_model)
varImpPlot(rf_model)
df <- read.csv ("Fire_With_Climate_Joined.csv")
df$fire_severity <- with(df, ifelse(frp==0,0,
ifelse(frp <= 50,1,2) ) )
df$fire_severity <- as.factor(df$fire_severity)
#Select predictor Variables
df_model <- df %>%
select(fire_severity, vpd, tmmx_C, pr, vs) %>%
na.omit()
#TRain test split
set.seed(123)
train_index <- createDataPartition(df_model$fire_severity, p = 0.7, list = FALSE)
train <- df_model[train_index, ]
test <- df_model[-train_index, ]
#  random forest classifier
rf_model <- randomForest(fire_severity ~ ., data = train, ntree= 100, importance=TRUE)
#Predictions on test set
preds<- predict(rf_model, newdata = test)
#Evaluate performance
conf_mat <- confusionMatrix(preds, test$fire_severity)
print(conf_mat)
# View variable importance
importance(rf_model)
varImpPlot(rf_model)
# Load required libraries
install.packages("ROSE")
library(ROSE)
library(ggplot2)
library(readr)
library(dplyr)
library(GGally)
library(randomForest)
library(caret)
# Load the data
df <- read_csv("Fire_With_Climate_Joined.csv")
#Handling Class Imbalances
# Read the merged dataset
df <- read.csv("Fire_With_Climate_Joined.csv")
# Step 1: Create fire severity variable based on frp
df$fire_severity <- with(df, ifelse(frp == 0, 0,
ifelse(frp <= 50, 1, 2)))
df$fire_severity <- as.factor(df$fire_severity)
# Step 2: Drop irrelevant or duplicate columns if needed
# (Remove frp and other IDs that shouldnâ€™t be predictors)
df <- df[, !(names(df) %in% c("frp", "acq_date", "acq_time", "satellite", "instrument", "confidence", "version", "daynight"))]
# Step 3: Train-test split (80-20)
set.seed(123)
split_index <- createDataPartition(df$fire_severity, p = 0.8, list = FALSE)
train <- df[split_index, ]
test <- df[-split_index, ]
# Step 4: Apply ROSE to balance the classes in the training set
balanced_train <- ovun.sample(fire_severity ~ .,
data = train,
method = "both",
N = nrow(train))$data
#Handling Class Imbalances
df$fire_severity <- with(df, ifelse(frp == 0, 0,
ifelse(frp <= 50, 1, 2)))
#Handling Class Imbalances
df <- read.csv("Fire_With_Climate_Joined.csv")
df$fire_severity <- with(df, ifelse(frp == 0, 0,
ifelse(frp <= 50, 1, 2)))
df$fire_severity <- as.factor(df$fire_severity)
#  Drop irrelevant or duplicate columns if needed
df <- df[, !(names(df) %in% c("frp", "acq_date", "acq_time", "satellite", "instrument", "confidence", "version", "daynight"))]
#  Train-test split (80-20)
set.seed(123)
split_index <- createDataPartition(df$fire_severity, p = 0.8, list = FALSE)
train <- df[split_index, ]
test <- df[-split_index, ]
#  Apply SMOTE to balance classes in training set
set.seed(123)
balanced_train <- SMOTE(fire_severity ~ ., data = train, perc.over = 300, perc.under = 150)
#Handling Class Imbalances
install.packages("DMwR")
library(DMwR)
#Handling Class Imbalances
install.packages("DMwR2")
library(DMwR2)
df <- read.csv("Fire_With_Climate_Joined.csv")
df$fire_severity <- with(df, ifelse(frp == 0, 0,
ifelse(frp <= 50, 1, 2)))
df$fire_severity <- as.factor(df$fire_severity)
#  Drop irrelevant or duplicate columns if needed
df <- df[, !(names(df) %in% c("frp", "acq_date", "acq_time", "satellite", "instrument", "confidence", "version", "daynight"))]
#  Train-test split (80-20)
set.seed(123)
split_index <- createDataPartition(df$fire_severity, p = 0.8, list = FALSE)
train <- df[split_index, ]
test <- df[-split_index, ]
#  Apply SMOTE to balance classes in training set
set.seed(123)
balanced_train <- SMOTE(fire_severity ~ ., data = train, perc.over = 300, perc.under = 150)
#Handling Class Imbalances
install.packages("DMwR2")
library(DMwR2)
df <- read.csv("Fire_With_Climate_Joined.csv")
df$fire_severity <- with(df, ifelse(frp == 0, 0,
ifelse(frp <= 50, 1, 2)))
df$fire_severity <- as.factor(df$fire_severity)
#  Drop irrelevant or duplicate columns if needed
df <- df[, !(names(df) %in% c("frp", "acq_date", "acq_time", "satellite", "instrument", "confidence", "version", "daynight"))]
#  Train-test split (80-20)
set.seed(123)
split_index <- createDataPartition(df$fire_severity, p = 0.8, list = FALSE)
train <- df[split_index, ]
test <- df[-split_index, ]
#  Apply SMOTE to balance classes in training set
library(DMwR2)
set.seed(123)
balanced_train <- SMOTE(fire_severity ~ ., data = train, perc.over = 300, perc.under = 150)
#Handling Class Imbalances
install.packages("DMwR2")
library(DMwR2)
df <- read.csv("Fire_With_Climate_Joined.csv")
df$fire_severity <- with(df, ifelse(frp == 0, 0,
ifelse(frp <= 50, 1, 2)))
df$fire_severity <- as.factor(df$fire_severity)
#  Drop irrelevant or duplicate columns if needed
df <- df[, !(names(df) %in% c("frp", "acq_date", "acq_time", "satellite", "instrument", "confidence", "version", "daynight"))]
#  Train-test split (80-20)
set.seed(123)
split_index <- createDataPartition(df$fire_severity, p = 0.8, list = FALSE)
train <- df[split_index, ]
test <- df[-split_index, ]
#  Apply SMOTE to balance classes in training set
library(DMwR2)
set.seed(123)
balanced_train <- SMOTE(fire_severity ~ ., data = train, perc.over = 300, perc.under = 150)
#Handling Class Imbalances
library(DMwR2)
df <- read.csv("Fire_With_Climate_Joined.csv")
df$fire_severity <- with(df, ifelse(frp == 0, 0,
ifelse(frp <= 50, 1, 2)))
df$fire_severity <- as.factor(df$fire_severity)
#  Drop irrelevant or duplicate columns if needed
df <- df[, !(names(df) %in% c("frp", "acq_date", "acq_time", "satellite", "instrument", "confidence", "version", "daynight"))]
#  Train-test split (80-20)
set.seed(123)
split_index <- createDataPartition(df$fire_severity, p = 0.8, list = FALSE)
train <- df[split_index, ]
test <- df[-split_index, ]
#  Apply SMOTE to balance classes in training set
library(DMwR2)
set.seed(123)
balanced_train <- SMOTE(fire_severity ~ ., data = train, perc.over = 300, perc.under = 150)
#Handling Class Imbalances
library(DMwR2)
df <- read.csv("Fire_With_Climate_Joined.csv")
df$fire_severity <- with(df, ifelse(frp == 0, 0,
ifelse(frp <= 50, 1, 2)))
df$fire_severity <- as.factor(df$fire_severity)
#  Drop irrelevant or duplicate columns if needed
df <- df[, !(names(df) %in% c("frp", "acq_date", "acq_time", "satellite", "instrument", "confidence", "version", "daynight"))]
#  Train-test split (80-20)
set.seed(123)
split_index <- createDataPartition(df$fire_severity, p = 0.8, list = FALSE)
train <- df[split_index, ]
test <- df[-split_index, ]
#  Apply SMOTE to balance classes in training set
library(DMwR2)
set.seed(123)
balanced_train <- DMwR2::SMOTE(fire_severity ~ ., data = train, perc.over = 300, perc.under = 150)
# 1. Load required packages
install.packages("smotefamily")
library(smotefamily)
library(randomForest)
library(caret)
# 2. Load your dataset
df <- read.csv("Fire_With_Climate_Joined.csv")
# 3. Create the fire_severity variable (3 classes: 0, 1, 2)
df$fire_severity <- with(df, ifelse(frp == 0, 0,
ifelse(frp <= 50, 1, 2)))
df$fire_severity <- as.factor(df$fire_severity)
# 4. Drop unneeded variables
df <- df[, !(names(df) %in% c("frp", "acq_date", "acq_time",
"satellite", "instrument", "confidence",
"version", "daynight"))]
# 5. Split into train/test (80/20)
set.seed(123)
split_index <- createDataPartition(df$fire_severity, p = 0.8, list = FALSE)
train <- df[split_index, ]
test  <- df[-split_index, ]
# 6. Convert target to numeric for smotefamily
train$fire_severity <- as.numeric(as.character(train$fire_severity))
# 7. Apply SMOTE (multiclass)
smote_result <- SMOTE(X = train[, -which(names(train) == "fire_severity")],
target = train$fire_severity,
K = 5,
dup_size = 0)
# 8. Combine predictors and target
balanced_train <- smote_result$data
colnames(balanced_train)[ncol(balanced_train)] <- "fire_severity"
balanced_train$fire_severity <- as.factor(balanced_train$fire_severity)
# 9. Fit random forest
rf_model <- randomForest(fire_severity ~ .,
data = balanced_train,
ntree = 100,
importance = TRUE)
# 10. Predict on test set
preds <- predict(rf_model, newdata = test)
# 11. Evaluate
conf_matrix <- confusionMatrix(preds, test$fire_severity)
print(conf_matrix)
# 12. Feature importance plot
varImpPlot(rf_model)
df <- read.csv ("Fire_With_Climate_Joined.csv")
df$fire_severity <- with(df, ifelse(frp==0,0,
ifelse(frp <= 50,1,2) ) )
df$fire_severity <- as.factor(df$fire_severity)
#Select predictor Variables
df_model <- df %>%
select(fire_severity, vpd, tmmx_C, pr, vs) %>%
na.omit()
#TRain test split
set.seed(123)
train_index <- createDataPartition(df_model$fire_severity, p = 0.7, list = FALSE)
train <- df_model[train_index, ]
test <- df_model[-train_index, ]
#  random forest classifier
rf_model <- randomForest(fire_severity ~ ., data = train, ntree= 100, importance=TRUE)
#Predictions on test set
preds<- predict(rf_model, newdata = test)
#Evaluate performance
conf_mat <- confusionMatrix(preds, test$fire_severity)
print(conf_mat)
# View variable importance
importance(rf_model)
varImpPlot(rf_model)
# 1. Load required packages
install.packages("smotefamily")
library(smotefamily)
library(randomForest)
library(caret)
# 2. Load your dataset
df <- read.csv("Fire_With_Climate_Joined.csv")
# 3. Create the fire_severity variable (3 classes: 0, 1, 2)
df$fire_severity <- with(df, ifelse(frp == 0, 0,
ifelse(frp <= 50, 1, 2)))
df$fire_severity <- as.factor(df$fire_severity)
# 4. Drop unneeded variables
df <- df[, !(names(df) %in% c("frp", "acq_date", "acq_time",
"satellite", "instrument", "confidence",
"version", "daynight"))]
# 5. Split into train/test (80/20)
set.seed(123)
split_index <- createDataPartition(df$fire_severity, p = 0.8, list = FALSE)
train <- df[split_index, ]
test  <- df[-split_index, ]
# 6. Convert target to numeric for smotefamily
train$fire_severity <- as.numeric(as.character(train$fire_severity))
# 7. Apply SMOTE (multiclass)
smote_result <- SMOTE(X = train[, -which(names(train) == "fire_severity")],
target = train$fire_severity,
K = 5,
dup_size = 0)
# 8. Combine predictors and target
balanced_train <- smote_result$data
colnames(balanced_train)[ncol(balanced_train)] <- "fire_severity"
balanced_train$fire_severity <- as.factor(balanced_train$fire_severity)
# 9. Fit random forest
rf_model <- randomForest(fire_severity ~ .,
data = balanced_train,
ntree = 100,
importance = TRUE)
# 10. Predict on test set
preds <- predict(rf_model, newdata = test)
# 11. Evaluate
conf_matrix <- confusionMatrix(preds, test$fire_severity)
print(conf_matrix)
# 12. Feature importance plot
varImpPlot(rf_model)
